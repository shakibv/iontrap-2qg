mode-6; mode 6 parameters
{
    mode 0         ; 0: Training | 1: Test | 2 : Debug

    py_dir  "/ion-trap-rl/"
    save_dir "./results/"

    max_xp      0.5
    max_rabi    2.0

    max_epi 100000
    termination_condition 0.9

    avg_window 100

    auto_qsd_simulation_seed 1 ; 0: Off | 1: On

    rl_agent
    {
        select "ppo"   ; ddpg | ppo

        ddpg
        {
            critic_lr       0.002   ; 0.002 learning rate for actor-critic models
            actor_lr        0.001   ; 0.001
            gamma           0.99    ; 0.99 discount factor for future rewards
            tau             0.005   ; 0.005 used to update target networks
            ou_noise_sd     0.2     ; 0.2
            buffer_capacity 2500
            batch_size      2500
        }

        ppo
        {
            critic_lr       0.0005  ; 0.0005 learning rate for actor-critic models
            actor_lr        0.0001  ; 0.0001
            epsilon         0.2     ; 0.2 amount of clipping surrogate objective
            entropy_weight  0.007   ; 0.007 rate of weighting entropy into the loss function
            gamma           0.9     ; 0.9 discount factor
            tau             0.8     ; 0.8 lambda of generalized advantage estimation (GAE)
            epoch           64      ; 64 the number of update
            batch_size      64      ; 64 batch size for sampling
            rollout_len     500     ; 500 the number of rollout
        }
    }
}